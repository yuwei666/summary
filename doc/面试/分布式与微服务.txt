分布式和微服务
（扫盲）现在流行的微服务解决方案有三种，分别是Dubbo+zookeeper、Spring cloud Neftlix、Spring Cloud alibaba

CAP理论
CAP理论是分布式领域中非常重要的一个指导理论，C（Consistency）表示强一致性，A（Availability）表示可靠性，P（Partition Tolerance）表示分区容错性，
CAP理论指出在目前的硬件条件下，一个分布式系统是必须要保证分区容错性的，而在这个前提下，分布式系统要么保证CP，要么保证AP，无法同时保证CAP。
	分区容错性：一个系统虽然是分布式的，但是对外看上去应该是一个整体，不能由于分布式系统内部的某个结点挂点，或网络出现了故障，而导致系统对外出现异常。
			所以，对于分布式系统而言是一定要保证分区容错性的。
	强一致性：一个分布式系统中各个结点之间能及时的同步数据，在数据同步过程中，是不能对外提供服务的，不然就会造成数据不一致，所以强一致性和可靠性是不能同时满足的。
	可靠性：一个分布式系统对外要保证可用

BASE理论
由于不能同时满足CAP，所以出现了BASE理论：
1. BA：Basically Available，表示基本可用，表示可以允许一定程度的不可用，如由于系统故障，请求时间变长，或者由于系统故障导致部分非核心功能不可用，都是允许的
2. S：Soft state：表示分布式系统可以处于一种中间状态，比如数据正在同步
3. E：Eventually consistent，表示最终一致性，不要求分布式系统数据实时达到一致，允许在经过一段时间后再达到一致，在达到一致过程中，系统也是可用的

什么是RPC
表示远程调用，在java中表示调用远程方法的方式，可以使用http协议，或者tcp协议来实现。

分布式id
1. uuid，最简单，但是影响存储空间和性能
2. 使用单机数据库的自增主键，受到单机数据库性能的影响，大并大量时不推荐
3. 利用redis的自增命令（redis.incr("xxxx")）、zookeeper的顺序节点
4. 雪花算法

分布式锁
zookeeper：利用zookeeper的临时节点、顺序节点、watch机制来实现的。zookeeper分布式锁的特点是高一致性，因为zk保证的是CP，所以它实现的分布式锁更可靠，不会混乱
redis：利用redis的setnx、lua脚本、消费机制来实现，redis分布式锁的特点是高可用性，因为zk保证的是AP，所以它实现的分布式锁可能不可靠，可能多个客户端同时加锁的情况

如何解决分布式事务
在分布式系统中，一次业务处理可能需要多个应用来实现，如用户发送一次下单请求，就涉及到订单系统创建订单、库存系统减库存，订单创建与减库存应该是要同时成功或同时失败
但在分布式系统中，如果不做处理，就很有可能出现订单创建成功，但是减库存失败，那么解决这类问题，就需要用到分布式事务。分布式事务基于两阶段提交解决的。
可以使用RocketMQ解决：RocketMQ支持事务消息，工作原理：
	a. 生产者订单系统先发送一条half消息到Broker，half消息对消费者而言是不可见的
	b. 再创建订单，根据创建订单成功与否，向Broker发送commit或rollback
	c. 并且生产者订单系统还可以提供Broker回调接口，当Broker发现一段时间half消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功
	d. 一旦half消息commit了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束
	e. 如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理

（扫盲）注册中心在分布式架构中起着非常重要的作用，可以心跳机制监测服务是否下线，可以收集服务的ip地址，端口，名称供消费者调用



zookeeper
为什么zookeer作为注册中心
可以利用zk的临时节点和watch机制来实现注册中心的自动注册和发现，另外zk的数据都是存在内存中的，并且底层适用了nio多线程模型，所以性能很好。
zk注重的是一致性，集群数据不一致时，集群将不可用；如果注重可用性，所以使用Redis，Ereka，Nacos更合适
*Nio线程模型：利用操作系统NIO的API实现，Java对其API的调用进行了封装

zk和Eureka的区别
ZK是强一致性（CP）的，当节点crash后，需要进行leader选举，在这个期间，zk不可用
Eureka是（AP）,各个节点是平等的，几个节点挂掉不影响正常工作。

zk的数据结构
zk底层是树形机构，主要维护的数据是客户端的会话（session）状态和节点信息
zk在内存中构造一个一颗DataTree，维护着path到DataNode的映射，以及dataNode间的树状层级关系。
树中的节点就是Znode，Znode可以作为路径标识，也可以存储数据，可以有子ZNode，支持增删改查操作
为了提高性能，集群中每个服务节点都是将数据全量存储在内存中。所以zk适合读多写少且轻量的数据的应用场景
数据仅存储在内存中是很不安全的，所以zk采用快照及日志的方式来落盘数据，保证数据能够快速恢复。

节点类型
持久节点：会一直存储在zk树上
临时节点：当创建该节点的客户端异常关闭时，该节点也会在zk树上删除
有序节点：上面两种节点基础上，增加了节点有序的性质

watch机制
客户端可以在Znode设置watch，实现监听Znode的事实变化
Watch事件是一个一次性的触发器，当被设置了watch的数据发生变化时，则服务器将这个改变发送给设置了watch的客户端
	父节点的创建、修改、删除会触发watch事件；子节点的创建，删除会触发watch事件

命名服务
通过名字获取资源和地址。zk中可以创建一个全局唯一的路径作为名字，被命名的实体可以是机器，服务的地址，或者远程对象，包括分布式框架（RPC）中的服务地址列表，
通过命名服务，可以根据特定的名字获取资源的实体，服务地址和提供者信息。
配置管理
实际项目开发中，需要配置很多信息，如数据库连接信息，fps地址端口。分布式部署时，把这些配置信息保存到zk的Znode节点下，当要修改信息，利用watch机制通知给各个客户端，从而更改配置。
集群管理
事实监控了Znode节点的变化，一旦有机器挂了，会断开与zk的连接，对应的临时节点会被删除，其他机器会收到通知。新机器加入也是如此

zookeeper如何实现一致性的
是通过ZAB协议实现的，ZAB协议是zookeeper用来实现一致性的原子广播协议。分为三个阶段：
	1. 领导者选举阶段  从zk集群中选举出一个节点作为Leader，所有的写请求会由Leader节点处理
	2. 数据同步阶段  集群中所有节点数据要与Leader节点保持一致，如果不一致会进行同步
	3. 请求广播阶段	 当Leader节点收到写请求时，会利用两阶段提交来广播该写请求，使得写请求像事务一样在其他节点执行，达到节点上的数据实时一致
zookeeper只是尽量达到强一致性，实际上仍然只是最终一致性

为什么zk节点是奇数
ZAP协议要求必须有过半节点能正常运行，奇数个节点能增加系统的容错能力；另外偶数节点在选举时，投票可能各占一半，无法选举。

zookeeper的选举流程
对于zk集群，整个集群需要从节点中选出一个Leader，流程如下：
1. 每个节点处于观望状态，先投票给自己
2. 然后互相投票，每个节点会收到其他节点发过来的选票，先比较zxid，如果相等则比较myid，如果输了则改票，将选票放入自己的投票箱内，并将新选票发送给其他节点
3. 经过多轮投票后，每个节点都会统计自己的选票，如果超过一半和自己投的一致，则投票的节点是Leader

zookeeper的节点之间数据同步
1. 集群启动时，进行选举确定Leader和Follower和Observer，然后Leader会和其他节点数据同步，采用快照和发送diff日志的形式
2. 集群在工作过程中，所有的写交给Leader处理，从节点只处理读。Leader在收到写请求时，会通过两阶段提交机制来处理
	Leader将写请求的日志发送给其他Follower节点，Follower收到日志后进行持久化，持久化成功则发送ACK确认给Leader，Leader收到半数以上的ACK，就会开始提交，更新Leader本地的内存数据
	然后发送commit给Follower节点，Follower收到后会更新各自的本地内存数据；同时Leader节点会将写请求发送给Observer，Observer收到请求后更新数据内存
	最后Leader节点响应客户端操作成功

Dubbo和Spring Cloud有哪些区别？
Spring Cloud是一个微服务框架，提供了很多微服务需要的组件，是一个大的框架；
Dubbo是一个Rpc调用框架，核心是解决服务间调用的问题，侧重于服务调用，没有Spring cloud全面，但是Dubbo的服务调用性能更高，两者也可以结合到一起使用

netty
主要用来做网络通信，可以用来做RPC框架的通信工作，比Http效率更高

Spring cloud alibaba
Nacos：注册中心、配置中心 	集群模式下负载均衡由nigix实现，cluster模式下持久化可以配置Mysql实现，单机不需要，有自带的数据库
		注册中心：服务启动时向Nacos注册服务
		配置中心：必须使用bootstrap.properties（.yml）配置Nacos Server地址。每10ms判断配置的md5是否发生变化，有变化重新拉取。
			@Value{”${xxx.xxx}“}需要配合@RefreshScope使用
Ribbon：负载均衡 利用@LoadBalanced 给restTemplate添加拦截器，先替换url中的服务id，从注册中心Nocas或Euruka获取所有服务列表后，根据负载均衡算法选择一个服务，最后发送请求
Feign：RPC调用  支持Spring mvc注解，整合了Nocos和Ribbon 
			启动类添加@EnableFeignClients，定义接口添加@FeignClient(name="服务名",path ="/xxx")、和方法@RequestMapping("/xxx")，直接通过正常@Autowired注入即可，还可以设置拦截器和日志级别
			本质还是动态代理
sentinal 服务熔断 保证服务高可用的场景 基于Nacos持久化
seata 分布式事务
gateway 微服务网关
skywalking 链路追踪


一致性Hash算法
应用在分布式系统中，当Redis中保存的数据达到一定量时，需要对Redis进行分区，数据按照hash算法分布到不同的Redis中。缺陷是服务器变动，需要重新计算hash值并移动位置。
一致性hash算法也是取模运算，hash算法是对固定长度取模，一致性hash算法是对2^32取模，此时hash桶不是一个固定长度的数组，而是一个hash环，
接下来用ip或主机名作为关键字参数hash运算，得到位于hash环上的位置
最后对redis的key进行hash运算，得到环上的位置，从该位置顺时针旋转，第一个redis实例就是所在的服务器

一致性Hash算法的容错性和可扩展性
一台redis不可用，只影响这个这个实例前面的redis实例，新增一台redis，只对这个redis后面的数据有影响，容错和扩展性比较好

Hash环数据倾斜的问题
如果节点太少可能会产生这个问题，所以引入了虚拟节点，每个节点计算多个hash，通常为32个

解决接口级故障的方式
降级 设计的时候，就考虑做一些开关，可以通过配置启停接口
熔断 分布式系统存在链式调用关系，
限流 


seata 分布式事务
AT模式
非侵入式的分布式事务解决方案，Seata在内部做了对数据库操作的代理层，使用的时候实际上是用自带的数据源代理DataSourceProxy，Seata在这层代理中加入了很多逻辑，比如undo_log，检查全局锁等。
	优点：简单易用，不需要改动业务代码，自动完成分布式事务的提交和回滚。 @GlobalTransaction
	缺点：不适合跨多种存储资源的事务，并且在高并发场景下性能可能出问题。
使用场景：CRUD较多的业务场景，尤其是当业务逻辑直接操作数据库，并且可以容忍短暂的数据库不一致时，AT模式通过记录数据的前后镜像来实现回滚操作
	
TCC模式
侵入式

SAGA模式


幂等性、空回滚、业务悬挂



